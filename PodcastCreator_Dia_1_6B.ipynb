{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPaD84B+AbxOviHNNDzG5h7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cburchett/podcastcreator/blob/main/PodcastCreator_Dia_1_6B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gradio"
      ],
      "metadata": {
        "id": "iMpzAkbKuKQI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2WZzjZw5JXN",
        "outputId": "97c26783-e000-4119-a221-c1d06d28af8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install directly from GitHub\n",
        "!pip -q install git+https://github.com/nari-labs/dia.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dia.model import Dia\n",
        "\n",
        "audio_model = Dia.from_pretrained(\"nari-labs/Dia-1.6B\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq-JBUlGxb5n",
        "outputId": "ae314450-a31b-4ef8-f6d6-e41ae65b7bbe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google import genai\n",
        "\n",
        "from google.colab import userdata\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = API_KEY\n",
        "\n",
        "# Create a client\n",
        "client = genai.Client(api_key=API_KEY)"
      ],
      "metadata": {
        "id": "iVs9W87Xbk6L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL_ID = \"gemini-2.5-pro-exp-03-25\"\n",
        "YOUTUBE_URL = \"https://www.youtube.com/watch?v=rSCaiHFRx0k\""
      ],
      "metadata": {
        "id": "Vzk684GblFZG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = \"\"\"Analyze the attached Youtube video.\n",
        "\n",
        "Based on the key topics, information, and events presented in the video, generate a medium length, conversational podcast script between two speakers, labeled S1 and S2.\n",
        "\n",
        "The script should summarize or discuss the main points of the video in a natural, back-and-forth dialogue format.\n",
        "\n",
        "**Crucially, format the output *exactly* as follows:**\n",
        "\n",
        "*   Each line of dialogue must start with either `[S1]` or `[S2]`.\n",
        "*   Follow the speaker tag with a space, then their dialogue.\n",
        "*   Present the dialogue turns sequentially, mimicking a conversation.\n",
        "*   Don't add any prefix or suffix to the conversation\n",
        "\n",
        "**Use this specific structure as your template:**\n",
        "\n",
        "```\n",
        "[S1] {Dialogue for speaker 1}\n",
        "[S2] {Dialogue for speaker 2}\n",
        "[S1] {Dialogue for speaker 1, potentially a reaction or follow-up}\n",
        "[S2] {Dialogue for speaker 2}\n",
        "[S1] {Dialogue for speaker 1}\n",
        "```\n",
        "\n",
        "**Example of the desired output format:**\n",
        "\n",
        "```\n",
        "[S1] Hey Sam, How are you? Let me tell you about Dia it's an open weights text to dialogue model.\n",
        "[S2] You get full control over scripts and voices.\n",
        "[S1] Wow. Amazing. (laughs)\n",
        "[S2] Try it now on Git hub or Hugging Face.\n",
        "[S1] You bet I will!\n",
        "```\n",
        "\n",
        "**Constraints:**\n",
        "\n",
        "*   Keep the turns relatively short and conversational.\n",
        "*   Focus on the core message or interesting aspects of the video.\n",
        "*   Adhere strictly to the `[S1]` / `[S2]` formatting.\n",
        "*   **Incorporate non-verbal cues where natural and appropriate.** These should be enclosed in parentheses within the dialogue line (e.g., `(laughs)` or `(sighs)`). You may use cues from this list: `(laughs)`, `(clears throat)`, `(sighs)`, `(gasps)`, `(coughs)`, `(singing)`, `(sings)`, `(mumbles)`, `(beep)`, `(groans)`, `(sniffs)`, `(claps)`, `(screams)`, `(inhales)`, `(exhales)`, `(applause)`, `(burps)`, `(humming)`, `(sneezes)`, `(whistles)`.\n",
        "*   Do not add any introductory text, explanations, or summaries outside of the formatted script itself.\n",
        "\n",
        "**Now, analyze the video and generate the script.**\n",
        "\n",
        "---\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "STB_P4fePBOE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def ensure_folder_exists():\n",
        "    now = datetime.now()\n",
        "    timestamp = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "    folder_path = '/content/' + timestamp\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "        print(f\"Folder '{folder_path}' created.\")\n",
        "    else:\n",
        "        print(f\"Folder '{folder_path}' already exists.\")\n",
        "    return folder_path"
      ],
      "metadata": {
        "id": "xKwJ6GHeneo9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "\n",
        "def generate_podcast_script(youtube_url, model, prompt):\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=types.Content(\n",
        "            parts=[\n",
        "                types.Part(text=prompt),\n",
        "                types.Part(\n",
        "                    file_data=types.FileData(file_uri=youtube_url)\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "    )\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "rYVTfmG3octh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def split_podcast_transcript(transcript, pairs):\n",
        "    \"\"\"Splits a podcast transcript into segments based on S1 and S2 pairs.\n",
        "\n",
        "    Args:\n",
        "        transcript: The podcast transcript as a string.\n",
        "\n",
        "    Returns:\n",
        "        A list of strings, where each string represents a segment of the transcript.\n",
        "        Returns an empty list if the input is invalid or no valid segments are found.\n",
        "    \"\"\"\n",
        "\n",
        "    segments = []\n",
        "    try:\n",
        "        # Split the transcript into lines\n",
        "        lines = transcript.strip().split('\\n')\n",
        "\n",
        "        # Use regular expressions to find S1 and S2 pairs\n",
        "        pattern = r\"\\[(S[12])\\](.*)\"\n",
        "        s1_s2_pairs = []\n",
        "        for line in lines:\n",
        "          match = re.match(pattern, line)\n",
        "          if match:\n",
        "            s1_s2_pairs.append(match.groups())\n",
        "\n",
        "        # Group lines into segments of three S1/S2 pairs\n",
        "        for i in range(0, len(s1_s2_pairs), pairs):\n",
        "            segment = \"\"\n",
        "            for j in range(i, min(i + pairs, len(s1_s2_pairs))):\n",
        "                segment += f\"[{s1_s2_pairs[j][0]}] {s1_s2_pairs[j][1]}\\n\"\n",
        "            segments.append(segment.strip())\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing transcript: {e}\")\n",
        "        return []\n",
        "\n",
        "    return segments"
      ],
      "metadata": {
        "id": "QhtHdTi4q3B3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def combine_mp3s(folder_path, output_file):\n",
        "    \"\"\"Combines all MP3 files in a folder into a single MP3 file.\n",
        "\n",
        "    Args:\n",
        "        folder_path: The path to the folder containing the MP3 files.\n",
        "        output_file: The path to the output MP3 file.\n",
        "    \"\"\"\n",
        "    combined = AudioSegment.empty()\n",
        "    file_list = os.listdir(folder_path)\n",
        "    file_list.sort()\n",
        "    for filename in file_list:\n",
        "        if filename.endswith(\".mp3\"):\n",
        "            filepath = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                segment = AudioSegment.from_mp3(filepath)\n",
        "                combined += segment\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {e}\")\n",
        "    combined.export(output_file, format=\"mp3\")\n",
        "    print(f\"Combined {len(file_list)} MP3 files into {output_file}\")\n",
        "    return output_file"
      ],
      "metadata": {
        "id": "VI4Ne5VSbzti"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "\n",
        "def generate_podcast(\n",
        "    transcript: str,\n",
        "    pairs: int,\n",
        "    max_new_tokens: int,\n",
        "    cfg_scale: float,\n",
        "    temperature: float,\n",
        "    top_p: float,\n",
        "    cfg_filter_top_k: int,\n",
        "    speed_factor: float,\n",
        "    ):\n",
        "\n",
        "    folder_path = ensure_folder_exists()\n",
        "\n",
        "    segments = split_podcast_transcript(transcript, pairs)\n",
        "    print(f\"Number of segments: \" + str(len(segments)))\n",
        "\n",
        "    for idx, seg in enumerate(segments):\n",
        "      print(f\"Generating segment {idx+1}\")\n",
        "      print(seg)\n",
        "      output = audio_model.generate(text=seg, max_tokens=max_new_tokens, cfg_scale=cfg_scale, temperature=temperature, top_p=top_p, cfg_filter_top_k=cfg_filter_top_k)\n",
        "      sf.write(folder_path + f\"/podcast_{idx+1}.mp3\", output, 44100)\n",
        "\n",
        "    return combine_mp3s(folder_path, folder_path + \"/finaL_podcast.mp3\")\n"
      ],
      "metadata": {
        "id": "Vgkn8Olhwunl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "ZaC9AnRRliXm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as podcast_script_generator:\n",
        "  gr.Markdown(\"## Podcast Generator\")\n",
        "  with gr.Tab(\"Script\"):\n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "        youtube_url = gr.Textbox(label=\"URL\", value=YOUTUBE_URL)\n",
        "        selected_model = gr.Dropdown([\"gemini-2.5-pro-exp-03-25\"])\n",
        "        system_prompt = gr.Textbox(label=\"System prompt\", value=PROMPT)\n",
        "        generate_script_button = gr.Button(\"Generate script\")\n",
        "      with gr.Column():\n",
        "        podcast_script = gr.Textbox(label=\"Podcast script\", lines=20)\n",
        "  generate_script_button.click(fn=generate_podcast_script, inputs=[youtube_url, selected_model, system_prompt], outputs=[podcast_script])\n",
        "\n",
        "  with gr.Tab(\"Podcast\"):\n",
        "     with gr.Row():\n",
        "       with gr.Column():\n",
        "          final_podcast_script = gr.Textbox(label=\"Final podcast script\", lines=20)\n",
        "          pairs = gr.Slider(\n",
        "                    label=\"Segment pairs\",\n",
        "                    minimum=1,\n",
        "                    maximum=10,\n",
        "                    value=2,  # Default from inference.py\n",
        "                    step=1,\n",
        "                    info=\"Higher values increase number of [S1] [S2] pairs will be in each batch.\",\n",
        "                )\n",
        "          with gr.Accordion(\"Generation Parameters\", open=False):\n",
        "                max_new_tokens = gr.Slider(\n",
        "                    label=\"Max New Tokens (Audio Length)\",\n",
        "                    minimum=860,\n",
        "                    maximum=3072,\n",
        "                    value=audio_model.config.data.audio_length,  # Use config default if available, else fallback\n",
        "                    step=50,\n",
        "                    info=\"Controls the maximum length of the generated audio (more tokens = longer audio).\",\n",
        "                )\n",
        "                cfg_scale = gr.Slider(\n",
        "                    label=\"CFG Scale (Guidance Strength)\",\n",
        "                    minimum=1.0,\n",
        "                    maximum=5.0,\n",
        "                    value=3.0,  # Default from inference.py\n",
        "                    step=0.1,\n",
        "                    info=\"Higher values increase adherence to the text prompt.\",\n",
        "                )\n",
        "                temperature = gr.Slider(\n",
        "                    label=\"Temperature (Randomness)\",\n",
        "                    minimum=1.0,\n",
        "                    maximum=1.5,\n",
        "                    value=1.3,  # Default from inference.py\n",
        "                    step=0.05,\n",
        "                    info=\"Lower values make the output more deterministic, higher values increase randomness.\",\n",
        "                )\n",
        "                top_p = gr.Slider(\n",
        "                    label=\"Top P (Nucleus Sampling)\",\n",
        "                    minimum=0.80,\n",
        "                    maximum=1.0,\n",
        "                    value=0.95,  # Default from inference.py\n",
        "                    step=0.01,\n",
        "                    info=\"Filters vocabulary to the most likely tokens cumulatively reaching probability P.\",\n",
        "                )\n",
        "                cfg_filter_top_k = gr.Slider(\n",
        "                    label=\"CFG Filter Top K\",\n",
        "                    minimum=15,\n",
        "                    maximum=50,\n",
        "                    value=30,\n",
        "                    step=1,\n",
        "                    info=\"Top k filter for CFG guidance.\",\n",
        "                )\n",
        "                speed_factor_slider = gr.Slider(\n",
        "                    label=\"Speed Factor\",\n",
        "                    minimum=0.8,\n",
        "                    maximum=1.0,\n",
        "                    value=0.94,\n",
        "                    step=0.02,\n",
        "                    info=\"Adjusts the speed of the generated audio (1.0 = original speed).\",\n",
        "                )\n",
        "          generate_podcast_button = gr.Button(\"Generate podcast\")\n",
        "       with gr.Column():\n",
        "          podcast_audio = gr.Audio(label=\"Final podcast audio\", type='filepath')\n",
        "  generate_podcast_button.click(fn=generate_podcast, inputs=[\n",
        "            final_podcast_script,\n",
        "            pairs,\n",
        "            max_new_tokens,\n",
        "            cfg_scale,\n",
        "            temperature,\n",
        "            top_p,\n",
        "            cfg_filter_top_k,\n",
        "            speed_factor_slider,], outputs=[podcast_audio])\n",
        "  podcast_script.change(fn=lambda x: x, inputs=podcast_script, outputs=final_podcast_script)\n",
        "\n",
        "podcast_script_generator.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ce_5emyBljKl",
        "outputId": "df01172c-72e7-4ea3-9f5c-d02952a75553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8a037483557a52af94.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8a037483557a52af94.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/2025-05-02 19:29:06' created.\n",
            "Number of segments: 7\n",
            "Generating segment 1\n",
            "[S1]  Hey, did you catch that NetApp video about AI and data infrastructure? It got me thinking about how much pressure AI is putting on traditional storage.\n",
            "[S2]  Totally. Tom Shields kicked it off by saying exactly that â€“ AI data pipelines are really straining storage architectures because the workloads are constantly evolving.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2146, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1664, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 884, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-11-36c5f95312a3>\", line 22, in generate_podcast\n",
            "    output = audio_model.generate(sec, max_new_tokens=max_new_tokens, cfg_scale=cfg_scale, temperature=temperature, top_p=top_p, cfg_filter_top_k=cfg_filter_top_k)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: Dia.generate() got an unexpected keyword argument 'max_new_tokens'\n"
          ]
        }
      ]
    }
  ]
}